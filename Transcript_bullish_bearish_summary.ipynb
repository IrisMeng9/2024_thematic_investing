{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrisMeng9/2024_thematic_investing/blob/main/Transcript_bullish_bearish_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTtP56aWLW_A"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade openai\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzAta-uCcKbJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtzx_16MWTxM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import json\n",
        "\n",
        "# Initialize model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "\n",
        "# Initialize sentiment pipeline\n",
        "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1-d983C7ZXk"
      },
      "outputs": [],
      "source": [
        "# Read all the parquet files from Renewable folder\n",
        "folder_path = \"//content/drive/MyDrive/capstone/transcript\"\n",
        "\n",
        "file_paths = glob.glob(os.path.join(folder_path, \"*.parquet\"))\n",
        "\n",
        "combined_df = pd.DataFrame()\n",
        "\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_parquet(file_path)\n",
        "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "symbol_list = combined_df['symbol'].unique().tolist()\n",
        "print(symbol_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWJ7rrmY3y5U"
      },
      "outputs": [],
      "source": [
        "combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA2D_vdbxBNI"
      },
      "outputs": [],
      "source": [
        "# Function to adjust sentiment classification\n",
        "def adjust_sentiment_classification(text, sentiment, score):\n",
        "    if \"costs increased\" in text or \"expenses increased\" in text:\n",
        "        return \"negative\", score\n",
        "    return sentiment, score\n",
        "\n",
        "# Perform sentiment classification\n",
        "results = []\n",
        "for index, row in combined_df.iterrows():\n",
        "    text = row['sentence_context']\n",
        "    sentiment_result = sentiment_pipeline(text)[0]\n",
        "    sentiment = sentiment_result['label']\n",
        "    score = sentiment_result['score']\n",
        "    adjusted_sentiment, adjusted_score = adjust_sentiment_classification(text, sentiment, score)\n",
        "    results.append({\n",
        "        **row,\n",
        "        \"classified_text\": {\n",
        "            \"predicted_value\": adjusted_sentiment,\n",
        "            \"prediction_probability\": adjusted_score,\n",
        "            \"model_id\": 'ProsusAI/finbert'\n",
        "        }\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Sentiment classification completed\")\n",
        "\n",
        "# Extract classified text into separate columns\n",
        "result_df['predicted_value'] = result_df['classified_text'].apply(lambda x: x['predicted_value'])\n",
        "result_df['prediction_probability'] = result_df['classified_text'].apply(lambda x: x['prediction_probability'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzJ2du4hh3a4"
      },
      "outputs": [],
      "source": [
        "result_df.to_excel('/content/drive/MyDrive/capstone/transcript/result_df.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0si_-dil95p9"
      },
      "source": [
        "## generate bullish/bearish statements for each company"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0-u5WRgxtpK"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = 'xxx'\n",
        "\n",
        "client = OpenAI(api_key = 'xxx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMgbOHJAxBS7"
      },
      "outputs": [],
      "source": [
        "# Function to extract top and bottom sentences by company\n",
        "def extract_top_bottom_sentences(company_symbol, df):\n",
        "    company_df = df[df['symbol'] == company_symbol]\n",
        "    top_positive = company_df[company_df['predicted_value'] == 'positive'].nlargest(10, 'prediction_probability')\n",
        "    top_negative = company_df[company_df['predicted_value'] == 'negative'].nlargest(10, 'prediction_probability')\n",
        "    return top_positive, top_negative\n",
        "\n",
        "# Function to create a summary using OpenAI\n",
        "def create_summary(symbol, top_positive, top_negative):\n",
        "    positive_sentences = \"\\n\".join([f\"Positive Sentence {i+1}: {row['sentence_context']}\" for i, row in top_positive.iterrows()])\n",
        "    negative_sentences = \"\\n\".join([f\"Negative Sentence {i+1}: {row['sentence_context']}\" for i, row in top_negative.iterrows()])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Company Symbol: {symbol}\n",
        "\n",
        "    Bullish (Positive) Sentences:\n",
        "    {positive_sentences}\n",
        "\n",
        "    Bearish (Negative) Sentences:\n",
        "    {negative_sentences}\n",
        "\n",
        "    Please provide a summarized bullish and bearish write-up for the company {symbol} in 150 words.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    summary = response.choices[0].message\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA70Kc1a9Ouh"
      },
      "outputs": [],
      "source": [
        "# Extract and summarize sentences for each company\n",
        "summaries = {}\n",
        "for symbol in symbol_list:\n",
        "    top_positive, top_negative = extract_top_bottom_sentences(symbol, result_df)\n",
        "    summary = create_summary(symbol, top_positive, top_negative)\n",
        "    summaries[symbol] = summary\n",
        "    print(f\"\\nSummary for {symbol}:\\n{summary}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KziIUNOJh8aE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# summary output\n",
        "string_summaries = {key: str(value) for key, value in summaries.items()}\n",
        "\n",
        "with open('summaries.json', 'w') as f:\n",
        "    json.dump(string_summaries, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUBygeNSxXtL"
      },
      "source": [
        "## Sector Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDl-JvccFYkR"
      },
      "outputs": [],
      "source": [
        "transcripts = []\n",
        "for index, row in combined_df.iterrows():\n",
        "    transcripts.append(row['sentence_context'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQESLqmLGhjJ"
      },
      "source": [
        "Here are the bullish and bearish summaries of each company:\n",
        "{summaries}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05AITbk1ZmsJ"
      },
      "outputs": [],
      "source": [
        "industry_writeup_prompt = f\"\"\"\n",
        " Here is the list of the companies in the AI sector we chose:\n",
        "{\", \".join(combined_df['symbol'].unique())}\n",
        "\n",
        "Here are the transcripts of each company: {transcripts}\n",
        "\n",
        "Based on the sentiment analysis above, please answer the following questions:\n",
        "1. What are these AI companies saying about important industry trends?\n",
        "2. What are companies in the AI sector saying about their growth outlook?\n",
        "3. What opportunities and challenges do these companies face?\n",
        "4. What risks should investors be aware of?\n",
        "5. What are the AI companies focising on ESG criteria?\n",
        "6. How does the AI companies performance vary between different market cycles?\n",
        "\n",
        "\n",
        "Summarize your responses in a detailed industry write-up.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": industry_writeup_prompt}\n",
        "    ],\n",
        "    max_tokens=10000,\n",
        "    temperature=0.5\n",
        ")\n",
        "# industry_writeup = response.choices[0].message\n",
        "print(\"Industry write-up completed\")\n",
        "# print(industry_writeup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdvQPkQDnita"
      },
      "outputs": [],
      "source": [
        "industry_writeup = response.choices[0].message.content.strip()\n",
        "print(industry_writeup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FccWh-YiWDYG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"AI companies are investing heavily in machine learning and data science.\",\n",
        "    \"Growth outlook for AI companies remains positive.\",\n",
        "    \"Challenges in the AI sector include data privacy and security.\",\n",
        "    \"Investors are optimistic about the opportunities in AI.\",\n",
        "    \"AI companies face risks such as regulatory changes.\"\n",
        "]\n",
        "\n",
        "# Step 1: Preprocess the text (already clean in this example)\n",
        "\n",
        "# Step 2: Vectorize the text\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "dtm = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Step 3: Apply LDA\n",
        "lda = LatentDirichletAllocation(n_components=2, random_state=0)\n",
        "lda.fit(dtm)\n",
        "\n",
        "# Step 4: Display the topics\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "display_topics(lda, vectorizer.get_feature_names_out(), 5)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}